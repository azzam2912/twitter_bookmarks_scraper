{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from datetime import datetime\n",
        "current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "JSON_FILE = 'bookmarks/twitter_bookmarks_20240903.json'\n",
        "PROCESSED_FOLDER = f'processed/{current_time}'\n",
        "CSV_FILE = PROCESSED_FOLDER + '/twitter_bookmarks.csv'\n",
        "CLEANED_JSON_FILE = PROCESSED_FOLDER + '/twitter_bookmarks_cleaned.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: bookmarks: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir $PROCESSED_FOLDER\n",
        "!mkdir 'bookmarks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Vnwux5-Pc35I"
      },
      "outputs": [],
      "source": [
        "def process_json_data_to_csv(json_data):\n",
        "  with open(CSV_FILE, 'a') as f:\n",
        "    f.write(\"counter,author,content,url,image_urls,video_urls\\n\")\n",
        "    for item in json_data:\n",
        "      counter = item.get('counter', '')\n",
        "      author = item.get('author', '')\n",
        "      content = item.get('content', '')\n",
        "      url = item.get('url', '')\n",
        "      image_urls = item.get('image_urls', '')\n",
        "      video_urls = item.get('video_urls', '')\n",
        "      f.write(f\"{counter},{author},{content},{url},{image_urls},{video_urls}\\n\")\n",
        "\n",
        "def process_json_data_to_json(json_data):\n",
        "  cleaned_data = []\n",
        "  counter = 1\n",
        "  for item in json_data:\n",
        "    item[\"counter\"] = str(counter)\n",
        "    counter+=1\n",
        "    for key in item:\n",
        "      if type(item[key]) == str:\n",
        "        item[key] = item[key].strip().replace('\\n', ' ').replace('\\t', ' ').replace(',', ' ')\n",
        "      elif type(item[key]) == list:\n",
        "        item[key] = ' '.join(item[key]).strip().replace('\\n', ' ').replace('\\t', ' ').replace(',', ' ')\n",
        "    cleaned_data.append(item)\n",
        "\n",
        "  import json\n",
        "  with open(CLEANED_JSON_FILE, 'w') as f:\n",
        "    json.dump(cleaned_data, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "4_OylDtxdPC_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(JSON_FILE, 'r') as f:\n",
        "  json_data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8AQhmmeqhFty"
      },
      "outputs": [],
      "source": [
        "process_json_data_to_json(json_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "d_9uceIPi11k"
      },
      "outputs": [],
      "source": [
        "with open(CLEANED_JSON_FILE, 'r') as f:\n",
        "  json_data_cleaned = json.load(f)\n",
        "\n",
        "process_json_data_to_csv(json_data_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "nu8wttMoeZfZ",
        "outputId": "ac75fa3a-a439-41a7-8842-7c573fdd5b31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>counter</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>url</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>video_urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>982</td>\n",
              "      <td>Namya @ Supafast @namyakhann · Aug 25  2023</td>\n",
              "      <td>As requested  here're 12 gray alternatives for...</td>\n",
              "      <td>https://x.com/namyakhann/status/16950056209766...</td>\n",
              "      <td>https://pbs.twimg.com/media/F4XeoPUaYAALPXl?fo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>983</td>\n",
              "      <td>ʞǝǝǝǝʎǝԀ @peyeeeek · Aug 24  2023</td>\n",
              "      <td>Monggo</td>\n",
              "      <td>https://x.com/peyeeeek/status/1694600639664541938</td>\n",
              "      <td>https://pbs.twimg.com/amplify_video_thumb/1694...</td>\n",
              "      <td>blob:https://x.com/d01de03f-1dfc-47f0-b848-e64...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>984</td>\n",
              "      <td>Gading Nasution ᵍⁿ @gadingnstn · Jul 2  2023</td>\n",
              "      <td>buat deploy BE + Database gratisan.  enakan ht...</td>\n",
              "      <td>https://x.com/gadingnstn/status/16754173495273...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>985</td>\n",
              "      <td>Ahnaf | Sukses Kuliah! @ahnafau · Jun 27  2023</td>\n",
              "      <td>Gimana cara mulai magang saat CV masih kosong?...</td>\n",
              "      <td>https://x.com/ahnafau/status/1673672800131842050</td>\n",
              "      <td>https://pbs.twimg.com/media/FzoUid5X0AEQ0pm?fo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>986</td>\n",
              "      <td>Eza \"Disclaimer\" Hazami @ezash · Mar 19  2023</td>\n",
              "      <td>Ada iPhone 5s ga kepake  semua fungsi normal d...</td>\n",
              "      <td>https://x.com/ezash/status/1637286495223693312</td>\n",
              "      <td>https://pbs.twimg.com/media/FrjPYaMaUAADsZi?fo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     counter                                          author  \\\n",
              "981      982     Namya @ Supafast @namyakhann · Aug 25  2023   \n",
              "982      983               ʞǝǝǝǝʎǝԀ @peyeeeek · Aug 24  2023   \n",
              "983      984    Gading Nasution ᵍⁿ @gadingnstn · Jul 2  2023   \n",
              "984      985  Ahnaf | Sukses Kuliah! @ahnafau · Jun 27  2023   \n",
              "985      986   Eza \"Disclaimer\" Hazami @ezash · Mar 19  2023   \n",
              "\n",
              "                                               content  \\\n",
              "981  As requested  here're 12 gray alternatives for...   \n",
              "982                                             Monggo   \n",
              "983  buat deploy BE + Database gratisan.  enakan ht...   \n",
              "984  Gimana cara mulai magang saat CV masih kosong?...   \n",
              "985  Ada iPhone 5s ga kepake  semua fungsi normal d...   \n",
              "\n",
              "                                                   url  \\\n",
              "981  https://x.com/namyakhann/status/16950056209766...   \n",
              "982  https://x.com/peyeeeek/status/1694600639664541938   \n",
              "983  https://x.com/gadingnstn/status/16754173495273...   \n",
              "984   https://x.com/ahnafau/status/1673672800131842050   \n",
              "985     https://x.com/ezash/status/1637286495223693312   \n",
              "\n",
              "                                            image_urls  \\\n",
              "981  https://pbs.twimg.com/media/F4XeoPUaYAALPXl?fo...   \n",
              "982  https://pbs.twimg.com/amplify_video_thumb/1694...   \n",
              "983                                                NaN   \n",
              "984  https://pbs.twimg.com/media/FzoUid5X0AEQ0pm?fo...   \n",
              "985  https://pbs.twimg.com/media/FrjPYaMaUAADsZi?fo...   \n",
              "\n",
              "                                            video_urls  \n",
              "981                                                NaN  \n",
              "982  blob:https://x.com/d01de03f-1dfc-47f0-b848-e64...  \n",
              "983                                                NaN  \n",
              "984                                                NaN  \n",
              "985                                                NaN  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(CSV_FILE, sep=',')\n",
        "df.tail(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Aq-nU5DalUUF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# dictionary where the value are dataframes\n",
        "term_dict = {}\n",
        "df_dict = {}\n",
        "name_list = [\"math\", \"idol\", \"tech\", \"other\"]\n",
        "\n",
        "term_dict[\"math\"] = [\"math\", \"find \", \"geometry\", \"other\", \"theorem\", \"puzzle\", \"TaghiBehradfar\",\n",
        "                     \"mirangu\", \"cetin\", \"solution\", \"barra\", \"calculate\", \"angle\", \"Ahmet____CETiN\"\n",
        "                     \"prove\", \"proof\", \"question\", \"silverbali7\", \"mathematical\", \"maths\", \n",
        "                     \"preshtalwalkar\", \"fermat\", \"viteric\", \"area\", \"maliuhudmuaz\", \"length\", \n",
        "                     \"diagonal\", \"figure\", \"midpoint\", \"Curios02435570\", \"elktrontrbyecsi\",\n",
        "                     \"castaneda_arcas\", \"1008138i\" ,\"cesscabral\", \"elktrontrbyecsi\", \"Hass12314\",\n",
        "                     \"bmhmr\"]\n",
        "term_dict[\"idol\"] = [\"idol\", \"oshi\", \"jkt48\", \"48\", \"lana\", \"erin\", \"elin\", \"ella\", \"peyeeeek\",\n",
        "                     \"yokanang\", \"greesel\", \"kamaniya\", \"lockscreen\", \"ofc\", \"photobook\",\n",
        "                     \"cynthia\", \"wota\",\"jeketi\", \"pajama\", \"cepio\", \"fiony\", \"aisa\",\n",
        "                     \"flora\", \"maeng\", \"icel\", \"kathy\", \"keti\", \"gracie\", \"rohmatkun\",\n",
        "                     \"emot\", \"neru\", \"andiano\", \"flyingglunt\", \"nagaginy\", \"regie\", \"moreen\", \n",
        "                     \"lily\", \"callie\", \"delynn\", \"cathy\", \"pappp99\", \"fritzy\",\n",
        "                     \"trisha\", \"chocofy\", \"omang\", \"chocolatpurple\", \"_hendraprnma\", \"dlayyyyyyyy\",\n",
        "                     \"Marshiegk\", \"michi\", \"motoshi_64\", \"gnitepun\", \"pocary_s\", \"dnthy\",\n",
        "                     \"piw piw\", \"rezaaagr\", \"putripramess\", \"oniel\", \"habisnontonfilm\",\n",
        "                     \"naisvv\", \"owenudinson\", \"rdnadn\", \"ZakZacky492655\", \"dagdigdugdeerr\", \n",
        "                     \"meledakduarduar\", \"ajkneptunn\", \"safarunithea\", \"fahriajaoke\", \"tgif\", \"hndprnma\",\n",
        "                     \"semaniscokl4t\", \"av__node\", \"parellzz\", \"versi_jelek\", \"amawmawa\", \"alfarosiyoga\", \n",
        "                     \"sokmatew\", \"fireodyssey\", \"hillaryours\", \"sonysoes\", \"nazarkinggg\", \"alipprangga\",\n",
        "                     \"kameeeha\"]\n",
        "term_dict[\"tech\"] = [\"code\",\"coding\", \"tech\", \"program\", \"web\", \"memory\", \"software\",\n",
        "                     \"dev\", \"engineer\", \"deploy\", \"backend\", \"frontend\",\n",
        "                     \"html\", \"javascript\", \"css\", \"js\", \"zakiego\", \"aria_ghora\", \"system\", \"react\",\n",
        "                     \"php\",\"lynxluna\", \"papanberjalan\", \"lwastuargo\", \"recursive\", \"git\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "RrHsWkwFvFWt"
      },
      "outputs": [],
      "source": [
        "for k in name_list:\n",
        "  df_dict[k] = pd.DataFrame(columns=[\"counter\", \"author\", \"content\", \"url\", \"image_urls\", \"video_urls\"])\n",
        "\n",
        "def classify_df(df, df_dict):\n",
        "  for index, row in df.iterrows():\n",
        "    content = str(row['content']).encode('ascii', 'ignore').decode().lower()\n",
        "    author = str(row['author']).encode('ascii', 'ignore').decode().lower()\n",
        "    found = False\n",
        "    query = content + \" \" + author\n",
        "    for key in term_dict.keys():\n",
        "      # make code below to check entire word, not just substring\n",
        "      if any(term.lower() in query for term in term_dict[key]):\n",
        "        df_dict[key].loc[len(df_dict[key])] = row\n",
        "        found = True\n",
        "        break\n",
        "    if not found:\n",
        "      df_dict[\"other\"].loc[len(df_dict[\"other\"])] = row\n",
        "\n",
        "def save_df_to_csv(df_dict):\n",
        "  for k, v in df_dict.items():\n",
        "    v.to_csv(PROCESSED_FOLDER + f\"/{k}.csv\", index=False)\n",
        "\n",
        "import csv\n",
        "import json\n",
        "\n",
        "def csv_to_json(csv_file_path, json_file_path):\n",
        "    # List to store the JSON data\n",
        "    json_data = []\n",
        "\n",
        "    # Read the CSV file\n",
        "    with open(csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.DictReader(csvfile)\n",
        "        \n",
        "        # Iterate through each row in the CSV\n",
        "        for row in csv_reader:\n",
        "            # Convert image_urls and video_urls to lists if they're not empty\n",
        "            row['image_urls'] = row['image_urls'].split(\" \") if row['image_urls'] else []\n",
        "            row['video_urls'] = row['video_urls'].split(\" \") if row['video_urls'] else []\n",
        "            \n",
        "            # Append the row to the JSON data list\n",
        "            json_data.append(row)\n",
        "\n",
        "    # Write the JSON data to a file\n",
        "    with open(json_file_path, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(json_data, jsonfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Conversion complete. JSON data saved to {json_file_path}\")\n",
        "\n",
        "# Example usage\n",
        "# csv_to_json('input.csv', 'output.json')\n",
        "\n",
        "def save_df_to_json(df_dict):\n",
        "  for k, v in df_dict.items():\n",
        "    csv_to_json(PROCESSED_FOLDER + f\"/{k}.csv\", PROCESSED_FOLDER + f\"/{k}.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "xxdP35WEvQAO"
      },
      "outputs": [],
      "source": [
        "classify_df(df, df_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K4tMNANzFSa",
        "outputId": "19abfd62-91c0-4718-e9a3-cd5d2e126617"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_dict[\"other\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLCvYHJu039V",
        "outputId": "d1c51ea2-b849-4e0f-e357-e9896362d80b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "986"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_dict[\"math\"])+len(df_dict[\"idol\"])+len(df_dict[\"tech\"])+len(df_dict[\"other\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "u0AxogOwrHX5"
      },
      "outputs": [],
      "source": [
        "# Call the function for each DataFrame\n",
        "save_df_to_csv(df_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversion complete. JSON data saved to processed/2024_09_03_14_28_40/math.json\n",
            "Conversion complete. JSON data saved to processed/2024_09_03_14_28_40/idol.json\n",
            "Conversion complete. JSON data saved to processed/2024_09_03_14_28_40/tech.json\n",
            "Conversion complete. JSON data saved to processed/2024_09_03_14_28_40/other.json\n"
          ]
        }
      ],
      "source": [
        "save_df_to_json(df_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = \"arman @armaniaghat · Feb 25 Fiverr and LinkedIn are trash!  Finding remote jobs is tough on these oversaturated sites.  So apply on these 7 sites instead:  (Pay USD)\"\n",
        "test1 = \"Ahnaf Sukses Kuliah! ahnafau 2023 Gimana cara mulai magang saat CV masih kosong? Yap itu pertanyaanku juga ketika dapat banyak penolakan magang.  Tapi kalian tau gak sih sekarang kita bisa apply magang di perusahaan besar dan PASTI KETERIMA + dapet sertifikat magang?  Mau spill gakk?\",\n",
        "test2 = \"Vicario Reinaldo vicarioreinaldo Aug 3 Meeting sering kali jadi formalitas aja dan ga efisien  Bukannya membantu malah sering ganggu tugas prioritas  Nah bikin target dan plan aja ga cukup  5 metode ini bisa bantu lo mengelola meeting dengan lebih efisien\"\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keti\n"
          ]
        }
      ],
      "source": [
        "for key in term_dict.keys():\n",
        "      for term in term_dict[key]:\n",
        "        if term.lower() in str(test1).strip().replace('\\n', ' ').replace('\\t', ' ').replace(',', ' ').lower():\n",
        "          print(term)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
